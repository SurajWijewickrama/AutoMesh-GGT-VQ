{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gevc4t__bsbq",
        "outputId": "a391f0de-6176-4071-9b23-2998abeb0d90"
      },
      "outputs": [],
      "source": [
        "# # prompt: get the drive connected to the notebook\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQ1DvgVqOMvK",
        "outputId": "3263a192-2a44-407d-cf01-9ccd01e61942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in d:\\suraj\\anaconda3\\lib\\site-packages (2.5.1)\n",
            "Requirement already satisfied: torch_geometric in d:\\suraj\\anaconda3\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: transformers in d:\\suraj\\anaconda3\\lib\\site-packages (4.48.0)\n",
            "Requirement already satisfied: numpy==1.26.4 in d:\\suraj\\anaconda3\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: filelock in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: networkx in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in d:\\suraj\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohttp in d:\\suraj\\anaconda3\\lib\\site-packages (from torch_geometric) (3.10.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
            "Requirement already satisfied: pyparsing in d:\\suraj\\anaconda3\\lib\\site-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in d:\\suraj\\anaconda3\\lib\\site-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in d:\\suraj\\anaconda3\\lib\\site-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\suraj\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\suraj\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in d:\\suraj\\anaconda3\\lib\\site-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in d:\\suraj\\anaconda3\\lib\\site-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: colorama in d:\\suraj\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\suraj\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\suraj\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\suraj\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.11.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in d:\\suraj\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\suraj\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\suraj\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\suraj\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\suraj\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2024.12.14)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ympy (D:\\SURAJ\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ympy (D:\\SURAJ\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ympy (D:\\SURAJ\\anaconda3\\Lib\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torch_geometric transformers numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the file specified.\n"
          ]
        }
      ],
      "source": [
        "pip install numpy<2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xHBi_C-sGbYG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "f14f5a8c778a4393933842e6737cb631",
            "7bb00053b88d47d684ded22fc79b7061",
            "6ec9249ba6364b8eb9c8cdee07d62f28",
            "b9b1310b2cc844b58d36f03ce2121df6",
            "0cd779ddf0be49bb857bbee186a8bdb5",
            "ab44d06347094ed5bc15e5ee232eac5f",
            "c2dcb84419e84f4c94b062e256c60fc7",
            "37ade2c5ac3e4fd38a02200c84bac548",
            "e8efdfafa7594d648715b7388115b6bc",
            "5ee3cfc2d2a64a5286907d9d1e1c5a13",
            "2397f1d2773d46ba8a3f408208293888",
            "97c440d79b63422bb1653f7f06a1a079",
            "b21fdc01b76b484f88ebff488171588a",
            "d56aa33f2cf843109608aad4a243c294",
            "c7ca3809b88b4a0b8668897452dbda7c",
            "2e9b5736d2414acda9d15ac96473c885",
            "51c8fafad03b49b993b1569ca396197b",
            "b628ae7a8f6544c286311ac4cae11eed",
            "bd21d9d2bfed40d8887ff97cbb571205",
            "97bdf1a4b7424908b96bd0454cd3a708",
            "d230aec0b9c540cc892ecd07012c404e",
            "134d780ed6c64778a4ce565339b61686",
            "e688fbce31824171994232209d5c43c3",
            "90e0bb2fe52e4080be9913569e83c314",
            "dbad3e0bf4104835abeb6966d9865d66",
            "607db37930064289878b1791b8ac7bd4",
            "b0658da51e9645af95ce49e50281cc6d",
            "6cbde44d11334b5b944c8410c8cb0d38",
            "f43b792d1ac142b4b29d3a6081b89646",
            "90fe37851c7a47138a7006eb54fcdd4d",
            "5971a7ddd8594a5cb9ec060168bc14ac",
            "0f0958f6189b4948926a236c26eb8c5f",
            "337eb33f480440a48149ce9c1a1aa4a6",
            "97c786a45441467b8d874fe5c25c6126",
            "cc7945f033b24db089f116da7ac98aeb",
            "9892b898f51540098e2fc72b6a41ebce",
            "d68069b8111e47b69365b3e3760d1edf",
            "29cb580877af43e586f4d76c288a6380",
            "5d15e1ab66e147eeb027ebf9d86bc435",
            "f1b416f44ddd4b4c9df5eef75978c6f4",
            "36355540013a4f78be3ca41e44b6926d",
            "a2a056a85c984797b34fa0fdb45a1298",
            "297b8c9d245f42a4864d853f0674aae6",
            "24027343e539405a95bb88f4cf0d5044",
            "97e43e3f2ff4430589ce42ac608b790c",
            "1093834e1ad84e52adc3155a979bc1a8",
            "9db512326f264814aa7c1172dc6c8ea3",
            "8002c62e95af4128b45b4759fd1ae9a7",
            "9de36e3c313a4a789a849204162e18dc",
            "6ebf19089e0f460aaa211c6ff1996b02",
            "bab982ff160a4d73b993ed5db2c49218",
            "382bc7f77d0d47f9ae4bbb00a40128e5",
            "5bbb1a78cf5b49feb35d9f1a3a55a8db",
            "f9a0986b39f6486f8a1ebcc597d744ba",
            "2e6617cbf36c4e91973b888cd244bf2b"
          ]
        },
        "id": "wVM39ezfKKpV",
        "outputId": "d86d5aff-67fa-4d95-aa20-68572ffa8d4a"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer, BertModel\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m BertModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-uncased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1806\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m   1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[1;32m-> 1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[0;32m   1808\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1803\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\utils\\import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_module\u001b[39m(\u001b[38;5;28mself\u001b[39m, module_name: \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1817\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1819\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1820\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1821\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1822\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:47\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_attn_mask_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     33\u001b[0m     _prepare_4d_attention_mask_for_sdpa,\n\u001b[0;32m     34\u001b[0m     _prepare_4d_causal_attention_mask_for_sdpa,\n\u001b[0;32m     35\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     37\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m     38\u001b[0m     BaseModelOutputWithPoolingAndCrossAttentions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     45\u001b[0m     TokenClassifierOutput,\n\u001b[0;32m     46\u001b[0m )\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m apply_chunking_to_forward, find_pruneable_heads_and_indices, prune_linear_layer\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     50\u001b[0m     ModelOutput,\n\u001b[0;32m     51\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m     replace_return_docstrings,\n\u001b[0;32m     57\u001b[0m )\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\modeling_utils.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mflex_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m flex_attention_forward\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegrations\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msdpa_attention\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sdpa_attention_forward\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LOSS_MAPPING\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     53\u001b[0m     Conv1D,\n\u001b[0;32m     54\u001b[0m     apply_chunking_to_forward,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     60\u001b[0m     translate_to_torch_parallel_style,\n\u001b[0;32m     61\u001b[0m )\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mquantizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoHfQuantizer, HfQuantizer\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_utils.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BCEWithLogitsLoss, MSELoss\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_deformable_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DeformableDetrForObjectDetectionLoss, DeformableDetrForSegmentationLoss\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ForObjectDetectionLoss, ForSegmentationLoss\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_rt_detr\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RTDetrForObjectDetectionLoss\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\loss\\loss_deformable_detr.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage_transforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m center_to_corners_format\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_scipy_available\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloss_for_object_detection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     HungarianMatcher,\n\u001b[0;32m      8\u001b[0m     ImageLoss,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     sigmoid_focal_loss,\n\u001b[0;32m     12\u001b[0m )\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\transformers\\image_transforms.py:50\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tf_available():\n\u001b[1;32m---> 50\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_flax_available():\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjax\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mjnp\u001b[39;00m\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py:467\u001b[0m\n\u001b[0;32m    465\u001b[0m     importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf_keras.src.optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    466\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 467\u001b[0m     importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeras.src.optimizers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    468\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m):\n\u001b[0;32m    469\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap\u001b[38;5;241m.\u001b[39m_gcd_import(name[level:], package, level)\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\keras\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DTypePolicy\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FloatDTypePolicy\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Function\n",
            "File \u001b[1;32md:\\SURAJ\\anaconda3\\Lib\\site-packages\\keras\\api\\__init__.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m legacy\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mixed_precision\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:991\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1087\u001b[0m, in \u001b[0;36mget_code\u001b[1;34m(self, fullname)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:1186\u001b[0m, in \u001b[0;36mget_data\u001b[1;34m(self, path)\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\").to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3bmcY6WOLLJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "def preprocess_object(obj, tokenizer=tokenizer, device=device):\n",
        "    # Extract graph data\n",
        "    vertices = torch.tensor(obj['v'], dtype=torch.float).to(device)  # Move to device\n",
        "    edges = torch.tensor(obj['e'], dtype=torch.long).t().to(device)  # Transpose and move to device\n",
        "\n",
        "    # Encode text label using BERT\n",
        "    text_label_str = obj['n']\n",
        "    inputs = tokenizer(text_label_str, return_tensors=\"pt\", padding=True, truncation=True, max_length=32)\n",
        "    input_ids = inputs[\"input_ids\"].to(dtype=torch.long)  # Ensure integer token IDs and move to device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bert_model(input_ids.to(device))  # Ensure input is on the correct device\n",
        "    text_label_embedding = outputs.last_hidden_state.to(device)  # Pool the embeddings and move to device\n",
        "    print(text_label_embedding.shape)\n",
        "    pooled_text_label = text_label_embedding.mean(dim=1)\n",
        "    # Create graph data\n",
        "    graph_data = Data(x=vertices, edge_index=edges, text_label=pooled_text_label)\n",
        "    \n",
        "    print(graph_data)\n",
        "    return graph_data\n",
        "\n",
        "def load_json(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "        return preprocess_object(data)\n",
        "\n",
        "def create_dataset(folder_path):\n",
        "    dataset = []\n",
        "    file_list = os.listdir(folder_path)\n",
        "    print(len(file_list))\n",
        "    for file_name in file_list:\n",
        "        if file_name.endswith('.json'):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            data = load_json(file_path)\n",
        "            dataset.append(data)\n",
        "            print(file_name)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1uCMzSSeFYPA"
      },
      "outputs": [],
      "source": [
        "# Dataset and DataLoader\n",
        "def load_data_and_split(folder_path, ):\n",
        "    dataset = create_dataset(folder_path)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = int(0.1 * len(dataset))\n",
        "    test_size = len(dataset) - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "        dataset, [train_size, val_size, test_size]\n",
        "    )\n",
        "    return train_dataset, val_dataset, test_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkzVXC5UWmhk",
        "outputId": "21d50b42-85ca-401b-998b-60fcdc3d00f0"
      },
      "outputs": [],
      "source": [
        "train_dataset, val_dataset, test_dataset = load_data_and_split('./sample')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# Function to visualize the 3D graph\n",
        "def visualize_3d(vertices, edges):\n",
        "    \"\"\"\n",
        "    Visualize a 3D graph given vertices and edges.\n",
        "\n",
        "    :param vertices: numpy array of shape (n, 3) representing the 3D coordinates of the vertices.\n",
        "    :param edges: numpy array of shape (2, m) where each column represents an edge (start_index, end_index).\n",
        "    \"\"\"\n",
        "    # Create a 3D plot\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "    # Ensure vertices are a numpy array\n",
        "    vertices = np.array(vertices)\n",
        "\n",
        "    # Plot vertices\n",
        "    ax.scatter(vertices[:, 0], vertices[:, 1], vertices[:, 2], c='b', marker='o', s=10, label=\"Vertices\")\n",
        "\n",
        "    # Plot edges\n",
        "    for i in range(edges.shape[1]):\n",
        "        v1, v2 = edges[:, i]  # Each column represents an edge (start_index, end_index)\n",
        "        ax.plot([vertices[v1, 0], vertices[v2, 0]],\n",
        "                [vertices[v1, 1], vertices[v2, 1]],\n",
        "                [vertices[v1, 2], vertices[v2, 2]], c='r', linewidth=1)\n",
        "\n",
        "    # Set plot labels\n",
        "    ax.set_xlabel('X Axis')\n",
        "    ax.set_ylabel('Y Axis')\n",
        "    ax.set_zlabel('Z Axis')\n",
        "    ax.legend()\n",
        "\n",
        "    # Set equal scaling for all axes\n",
        "    max_range = np.array([vertices[:, 0].max() - vertices[:, 0].min(),\n",
        "                          vertices[:, 1].max() - vertices[:, 1].min(),\n",
        "                          vertices[:, 2].max() - vertices[:, 2].min()]).max() / 2.0\n",
        "\n",
        "    mid_x = (vertices[:, 0].max() + vertices[:, 0].min()) * 0.5\n",
        "    mid_y = (vertices[:, 1].max() + vertices[:, 1].min()) * 0.5\n",
        "    mid_z = (vertices[:, 2].max() + vertices[:, 2].min()) * 0.5\n",
        "    ax.set_xlim(mid_x - max_range, mid_x + max_range)\n",
        "    ax.set_ylim(mid_y - max_range, mid_y + max_range)\n",
        "    ax.set_zlim(mid_z - max_range, mid_z + max_range)\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "# Extract vertices and edges from the dataset\n",
        "vertices_np, edges_np, text_label = train_dataset[1].x.cpu().numpy(), train_dataset[1].edge_index.cpu().numpy(),train_dataset[1].text_label.cpu().numpy()\n",
        "\n",
        "# Print the first graph's data for verification\n",
        "print(\"Vertices:\", vertices_np)\n",
        "print(\"Edges:\", edges_np)\n",
        "print(\"Text:\", text_label)\n",
        "\n",
        "# Visualize the first graph\n",
        "visualize_3d(vertices_np, edges_np)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class NodeCountPredictor(nn.Module):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(NodeCountPredictor, self).__init__()\n",
        "        self.node_count_predictor = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1),  # Predict a single scalar\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            z: Latent representation [batch_size, latent_dim]\n",
        "        Returns:\n",
        "            predicted_node_count: Scalar prediction for the number of nodes\n",
        "        \"\"\"\n",
        "        return self.node_count_predictor(z).squeeze(-1)\n",
        "\n",
        "def pretrain_node_count_predictor(predictor, data_loader, optimizer, device, num_epochs=10):\n",
        "    predictor.train()\n",
        "    loss_fn = nn.MSELoss()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        for data in data_loader:\n",
        "            data = data.to(device)\n",
        "            z = data.latent_vector  # Use precomputed latent vector\n",
        "            true_num_nodes = data.num_nodes  # Ground truth node count\n",
        "            \n",
        "            # Forward pass\n",
        "            predicted_num_nodes = predictor(z)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = loss_fn(predicted_num_nodes, true_num_nodes.float())\n",
        "            \n",
        "            # Backpropagation\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(data_loader):.4f}\")\n",
        "\n",
        "\n",
        "NodeCountPredictor()\n",
        "pretrain_node_count_predictor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "oIKuwwe9fOMw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv, GATConv\n",
        "\n",
        "# Transformer Encoder\n",
        "class TransformerTextEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, num_layers):\n",
        "        super(TransformerTextEncoder, self).__init__()\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "\n",
        "    def forward(self, text_input):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            text_input: Tensor of shape [batch_size, seq_len, embed_dim]\n",
        "        Returns:\n",
        "            encoded_text: Tensor of shape [batch_size, seq_len, embed_dim]\n",
        "        \"\"\"\n",
        "        # Transpose to match Transformer input format: [seq_len, batch_size, embed_dim]\n",
        "        text_input = text_input.permute(1, 0, 2)\n",
        "\n",
        "        # Encode text\n",
        "        encoded_text = self.transformer(text_input)  # Shape: [seq_len, batch_size, embed_dim]\n",
        "\n",
        "        # Transpose back to [batch_size, seq_len, embed_dim]\n",
        "        return encoded_text.permute(1, 0, 2)\n",
        "\n",
        "\n",
        "# Graph Encoder (GNN)\n",
        "class GraphEncoder(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers):\n",
        "        super(GraphEncoder, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.layers.append(GCNConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.layers.append(GCNConv(hidden_channels, hidden_channels))\n",
        "        self.layers.append(GCNConv(hidden_channels, out_channels))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for layer in self.layers:\n",
        "            x = F.relu(layer(x, edge_index))\n",
        "        return x.mean(dim=0)  # Pooling to get latent feature z_G\n",
        "\n",
        "# Feature Fusion\n",
        "class FeatureFusion(nn.Module):\n",
        "    def __init__(self, text_dim, graph_dim, fused_dim):\n",
        "        super(FeatureFusion, self).__init__()\n",
        "        self.fc = nn.Linear(text_dim + graph_dim, fused_dim)\n",
        "\n",
        "    def forward(self, c_text, z_G):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            c_text: Encoded text from the Transformer [batch_size, seq_len, embed_dim]\n",
        "            z_G: Encoded graph representation [batch_size, graph_dim]\n",
        "        Returns:\n",
        "            fused_features: Combined features [batch_size, fused_dim]\n",
        "        \"\"\"\n",
        "\n",
        "        # Pool the sequence dimension of c_text\n",
        "        c_text_pooled = c_text.mean(dim=1)  # Shape: [batch_size, text_dim]\n",
        "\n",
        "        # Match dimensions of c_text and z_G\n",
        "        if c_text_pooled.ndim == 2 and z_G.ndim == 1:\n",
        "            z_G = z_G.unsqueeze(0).expand(c_text_pooled.size(0), -1)\n",
        "\n",
        "        # Concatenate features and pass through the fully connected layer\n",
        "        combined_features = torch.cat([c_text_pooled, z_G], dim=-1)  # Shape: [batch_size, text_dim + graph_dim]\n",
        "        fused_features = self.fc(combined_features)  # Shape: [batch_size, fused_dim]\n",
        "        return fused_features\n",
        "\n",
        "\n",
        "# Vector Quantization (VQ)\n",
        "class VectorQuantization(nn.Module):\n",
        "    def __init__(self, codebook_size, embedding_dim):\n",
        "        super(VectorQuantization, self).__init__()\n",
        "        self.codebook = nn.Embedding(codebook_size, embedding_dim)\n",
        "        self.codebook.weight.data.uniform_(-1 / codebook_size, 1 / codebook_size)\n",
        "\n",
        "    def forward(self, z):\n",
        "        z_flattened = z.view(-1, z.size(-1))\n",
        "        distances = (torch.sum(z_flattened**2, dim=1, keepdim=True)\n",
        "                     - 2 * torch.matmul(z_flattened, self.codebook.weight.T)\n",
        "                     + torch.sum(self.codebook.weight**2, dim=1))\n",
        "        encoding_indices = torch.argmin(distances, dim=1)\n",
        "        z_q = self.codebook(encoding_indices).view(z.shape)\n",
        "        return z_q, encoding_indices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "class GraphDecoder(nn.Module):\n",
        "    def __init__(self, latent_dim, node_dim):\n",
        "        super(GraphDecoder, self).__init__()\n",
        "        self.node_decoder = nn.Linear(latent_dim, node_dim)\n",
        "        self.node_count_predictor = nn.Sequential(\n",
        "            nn.Linear(latent_dim, 1),\n",
        "            nn.ReLU()  # Ensure non-negative outputs\n",
        "        )\n",
        "        self.node_count_predictor[0].weight.data.uniform_(0.1, 1.0)\n",
        "        self.node_count_predictor[0].bias.data.fill_(10)  # Initialize bias to a higher value\n",
        "\n",
        "\n",
        "    def forward(self, z,true_num_nodes=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            z: Latent representation [batch_size, latent_dim]\n",
        "        Returns:\n",
        "            reconstructed_nodes: Tensor of shape [num_predicted_nodes, node_dim]\n",
        "            reconstructed_adj: Tensor of shape [num_predicted_nodes, num_predicted_nodes]\n",
        "        \"\"\"\n",
        "        batch_size = z.size(0)\n",
        "        assert batch_size == 1, \"Currently, this decoder supports only batch_size=1.\"\n",
        "\n",
        "        # Predict the number of nodes\n",
        "        raw_node_counts = self.node_count_predictor(z).squeeze(-1)  # Shape: [batch_size]\n",
        "        predicted_num_nodes = torch.clamp(raw_node_counts.round(), min=50, max=10000).long().item()  # Scalar: num_nodes\n",
        "\n",
        "        # Expand latent vector for node decoding\n",
        "        if(true_num_nodes==1):\n",
        "            z_expanded = z.expand(predicted_num_nodes, -1)  # [predicted_num_nodes, latent_dim]\n",
        "        else:\n",
        "            z_expanded = z.expand(true_num_nodes, -1)  # [predicted_num_nodes, latent_dim]\n",
        "\n",
        "        # Decode nodes\n",
        "        reconstructed_nodes = self.node_decoder(z_expanded)  # [predicted_num_nodes, node_dim]\n",
        "\n",
        "        # Decode adjacency matrix using pairwise similarity\n",
        "        reconstructed_adj = torch.sigmoid(torch.matmul(z_expanded, z_expanded.T))  # [predicted_num_nodes, predicted_num_nodes]\n",
        "\n",
        "        return reconstructed_nodes, reconstructed_adj\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TransformerGraphDecoder(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, num_layers, vocab_size):\n",
        "        super(TransformerGraphDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.positional_encoding = nn.Parameter(torch.zeros(1, 100, embed_dim))  # Adjust max sequence length\n",
        "        self.decoder = nn.TransformerDecoder(\n",
        "            nn.TransformerDecoderLayer(d_model=embed_dim, nhead=num_heads),\n",
        "            num_layers=num_layers\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embed_dim, vocab_size)\n",
        "\n",
        "    def forward(self, tgt, memory):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tgt: Target sequence [batch_size, seq_len]\n",
        "            memory: Encoded memory from the Transformer Encoder [batch_size, seq_len, embed_dim]\n",
        "\n",
        "        Returns:\n",
        "            Output logits for graph tokens [batch_size, seq_len, vocab_size]\n",
        "        \"\"\"\n",
        "        tgt_embedded = self.embedding(tgt) + self.positional_encoding[:, :tgt.size(1), :]\n",
        "        tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "        output = self.decoder(tgt_embedded.transpose(0, 1), memory.transpose(0, 1), tgt_mask).transpose(0, 1)\n",
        "        logits = self.fc_out(output)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "ZomqeACKU5O7",
        "outputId": "5560fa31-4c02-4912-c457-b7adad0890dc"
      },
      "outputs": [],
      "source": [
        "import torch                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.utils import to_dense_adj\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "\n",
        "def set_mode(model, mode=\"train\"):\n",
        "    \"\"\"\n",
        "    Set all components of the model to train or eval mode.\n",
        "    Args:\n",
        "        model (dict): Dictionary of model components.\n",
        "        mode (str): \"train\" or \"eval\".\n",
        "    \"\"\"\n",
        "    for component in model.values():\n",
        "        if mode == \"train\":\n",
        "            component.train()\n",
        "        elif mode == \"eval\":\n",
        "            component.eval()\n",
        "\n",
        "# Training Function\n",
        "def pad_tensor(tensor, target_shape, padding_value=0.0):\n",
        "    \"\"\"\n",
        "    Pads or truncates a tensor to the target shape.\n",
        "    Args:\n",
        "        tensor (torch.Tensor): Input tensor.\n",
        "        target_shape (tuple): Desired shape after padding.\n",
        "        padding_value (float): Value for padding.\n",
        "    Returns:\n",
        "        torch.Tensor: Padded/truncated tensor.\n",
        "    \"\"\"\n",
        "    padded_tensor = torch.full(target_shape, padding_value, device=tensor.device, dtype=tensor.dtype)\n",
        "\n",
        "    # Calculate slices for assignment\n",
        "    slices = tuple(slice(0, min(s, t)) for s, t in zip(tensor.shape, target_shape))\n",
        "    padded_tensor[slices] = tensor[slices]\n",
        "    return padded_tensor\n",
        "\n",
        "def compute_node_count_loss(predicted_num_nodes, true_num_nodes):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        predicted_num_nodes: Scalar - Number of nodes predicted by the model.\n",
        "        true_num_nodes: Scalar - Ground truth number of nodes.\n",
        "    Returns:\n",
        "        node_count_loss: Loss for node count prediction.\n",
        "    \"\"\"\n",
        "    return F.mse_loss(predicted_num_nodes.float(), true_num_nodes.float())\n",
        "def compute_loss(reconstructed_nodes, ground_truth_nodes, reconstructed_adj, ground_truth_adj, true_num_nodes, predicted_num_nodes):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        reconstructed_nodes: Predicted node features [num_predicted_nodes, node_dim].\n",
        "        ground_truth_nodes: Ground truth node features [num_true_nodes, node_dim].\n",
        "        reconstructed_adj: Predicted adjacency matrix [num_predicted_nodes, num_predicted_nodes].\n",
        "        ground_truth_adj: Ground truth adjacency matrix [num_true_nodes, num_true_nodes].\n",
        "        true_num_nodes: Scalar - Number of nodes in the ground truth graph.\n",
        "        predicted_num_nodes: Scalar - Number of nodes predicted by the model.\n",
        "    Returns:\n",
        "        loss: Total reconstruction loss (nodes + adjacency).\n",
        "    \"\"\"\n",
        "    # Determine the max size for alignment\n",
        "    max_nodes = max(true_num_nodes, predicted_num_nodes)\n",
        "\n",
        "    # Pad predicted outputs\n",
        "    reconstructed_nodes_padded = pad_tensor(reconstructed_nodes, (max_nodes, ground_truth_nodes.size(-1)))\n",
        "    reconstructed_adj_padded = pad_tensor(reconstructed_adj, (max_nodes, max_nodes))\n",
        "\n",
        "    # Pad ground truth\n",
        "    ground_truth_nodes_padded = pad_tensor(ground_truth_nodes, (max_nodes, ground_truth_nodes.size(-1)))\n",
        "    ground_truth_adj_padded = pad_tensor(ground_truth_adj, (max_nodes, max_nodes))\n",
        "\n",
        "    # Create a mask for valid nodes\n",
        "    mask = torch.arange(max_nodes, device=ground_truth_nodes.device) < true_num_nodes\n",
        "\n",
        "    # Node reconstruction loss\n",
        "    loss_nodes = F.mse_loss(\n",
        "        reconstructed_nodes_padded[mask],\n",
        "        ground_truth_nodes_padded[mask]\n",
        "    )\n",
        "\n",
        "    # Adjacency reconstruction loss\n",
        "    adj_mask = mask.unsqueeze(1) & mask.unsqueeze(0)\n",
        "    loss_adj = F.mse_loss(\n",
        "        reconstructed_adj_padded[adj_mask],\n",
        "        ground_truth_adj_padded[adj_mask]\n",
        "    )\n",
        "\n",
        "    return loss_nodes + loss_adj\n",
        "\n",
        "\n",
        "def train_one_epoch(model, data_loader, optimizer, device,epoch):\n",
        "    set_mode(model, mode=\"train\")\n",
        "    total_loss = 0\n",
        "    max_nodes = 6000  # Define the maximum number of nodes for padding\n",
        "    print(\"Training\", len(data_loader))\n",
        "    \n",
        "    for data in data_loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Inputs\n",
        "        text_input = data.text_label  # Use the text_label from the data\n",
        "        graph_x = data.x  # Node features\n",
        "        edge_index = data.edge_index  # Edge indices\n",
        "\n",
        "        # Forward pass\n",
        "        c_text = model['text_encoder'](text_input.unsqueeze(1))  # Encode text\n",
        "        z_G = model['graph_encoder'](graph_x, edge_index)  # Encode graph\n",
        "        \n",
        "        fused_features = model['feature_fusion'](c_text, z_G)  # Fuse features\n",
        "        z_qG, _ = model['vector_quantizer'](fused_features)  # Quantize\n",
        "        \n",
        "        if(epoch<25):\n",
        "            reconstructed_nodes, reconstructed_adj = model['graph_decoder'](z_qG,graph_x.size(0))  # Decode\n",
        "        else:\n",
        "            reconstructed_nodes, reconstructed_adj = model['graph_decoder'](z_qG,1)  # Decode\n",
        "\n",
        "        \n",
        "        \n",
        "        # Ground truth adjacency matrix (dense)\n",
        "        target_adj = to_dense_adj(edge_index).squeeze(0)\n",
        "        \n",
        "# Predict number of nodes\n",
        "        predicted_num_nodes = reconstructed_nodes.size(0)\n",
        "\n",
        "# Compute node count loss\n",
        "        node_count_loss = compute_node_count_loss(\n",
        "            torch.tensor(predicted_num_nodes, device=device),  # Convert scalar to tensor\n",
        "            torch.tensor(graph_x.size(0), device=device)\n",
        "        )\n",
        "\n",
        "# Combine with reconstruction loss\n",
        "        reconstruction_loss = compute_loss(\n",
        "            reconstructed_nodes,\n",
        "            graph_x,\n",
        "            reconstructed_adj,\n",
        "            target_adj,\n",
        "            graph_x.size(0),\n",
        "            predicted_num_nodes\n",
        "        )\n",
        "        loss = reconstruction_loss   # Add node count loss with a weight\n",
        "\n",
        "        # G\n",
        "        # loss_nodes = F.mse_loss(reconstructed_nodes_padded, graph_x_padded)\n",
        "        # loss_adj = F.mse_loss(reconstructed_adj_padded, target_adj_padded)\n",
        "        # loss = loss_nodes + loss_adj\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    set_mode(model, mode=\"eval\")\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            data = data.to(device)\n",
        "\n",
        "            # Inputs\n",
        "            text_input = data.text_label  # Use the text_label from the data\n",
        "            graph_x = data.x  # Node features\n",
        "            edge_index = data.edge_index  # Edge indices\n",
        "\n",
        "            # Forward pass\n",
        "            c_text = model['text_encoder'](text_input.unsqueeze(1))  # Encode text\n",
        "            z_G = model['graph_encoder'](graph_x, edge_index)  # Encode graph\n",
        "            \n",
        "            fused_features = model['feature_fusion'](c_text, z_G)  # Fuse features\n",
        "            z_qG, _ = model['vector_quantizer'](fused_features)  # Quantize\n",
        "            reconstructed_nodes, reconstructed_adj = model['graph_decoder'](z_qG,graph_x.size(0))  # Decode\n",
        "\n",
        "            # Ground truth adjacency matrix (dense)\n",
        "            target_adj = to_dense_adj(edge_index).squeeze(0)\n",
        "\n",
        "            # Compute loss\n",
        "            predicted_num_nodes = reconstructed_nodes.size(0)\n",
        "            \n",
        "            print (\"reconstructed_nodes\", reconstructed_nodes.shape)\n",
        "            print (\"graph_x\", graph_x.shape)\n",
        "            \n",
        "            loss = compute_loss(\n",
        "                reconstructed_nodes,\n",
        "                graph_x,\n",
        "                reconstructed_adj,\n",
        "                target_adj,\n",
        "                graph_x.size(0),\n",
        "                predicted_num_nodes\n",
        "            )\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n",
        "\n",
        "\n",
        "# Model components\n",
        "model = {\n",
        "        \"text_encoder\": TransformerTextEncoder(embed_dim=768, num_heads=4, num_layers=2).to(device),\n",
        "        \"graph_encoder\": GraphEncoder(in_channels=3, hidden_channels=32, out_channels=64, num_layers=3).to(device),\n",
        "        \"feature_fusion\": FeatureFusion(text_dim=768, graph_dim=64, fused_dim=128).to(device),\n",
        "        \"vector_quantizer\": VectorQuantization(codebook_size=512, embedding_dim=128).to(device),\n",
        "        \"graph_decoder\": GraphDecoder(latent_dim=128, node_dim=3).to(device),\n",
        "        \"transformer_decoder\": TransformerGraphDecoder(embed_dim=128, num_heads=4, num_layers=2, vocab_size=100).to(device)\n",
        "    }\n",
        "# Main Training Loop\n",
        "def main_training(num_epochs=10, batch_size=1, learning_rate=1e-4):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = Adam(\n",
        "        [param for part in model.values() for param in part.parameters()],\n",
        "        lr=learning_rate,\n",
        "    )\n",
        "\n",
        "    # Load Data\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_one_epoch(model, train_loader, optimizer, device,epoch)\n",
        "        val_loss = evaluate(model, val_loader, device)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"Training Complete!\")\n",
        "\n",
        "    # Testing\n",
        "    test_loss = evaluate(model, test_loader, device)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    \n",
        "# Run the training\n",
        "main_training()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_TD_one_epoch(model, data_loader, optimizer, device):\n",
        "    set_mode(model, mode=\"train\")\n",
        "    total_loss = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        # Extract graph features\n",
        "        graph_x = data.x  # Node features\n",
        "        edge_index = data.edge_index  # Edge indices\n",
        "        text_input = data.text_label  # Tokenized text input\n",
        "\n",
        "        # Compute graph tokens dynamically\n",
        "        z_G = model['graph_encoder'](graph_x, edge_index)  # [num_nodes, latent_dim]\n",
        "        c_text = model['text_encoder'](text_input.unsqueeze(1))\n",
        "        fused_features = model['feature_fusion'](c_text, z_G)  # [batch_size, fused_dim]\n",
        "\n",
        "        # Quantize fused features\n",
        "        z_qG, encoding_indices = model['vector_quantizer'](fused_features)\n",
        "\n",
        "        # Add batch dimension if necessary\n",
        "        z_qG = z_qG.unsqueeze(0) if z_qG.ndim == 2 else z_qG  # Ensure shape: [batch_size, seq_len, latent_dim]\n",
        "        encoding_indices = encoding_indices.unsqueeze(0) if encoding_indices.ndim == 1 else encoding_indices  # Ensure shape: [batch_size, seq_len]\n",
        "\n",
        "        # Prepare target input and output for the decoder\n",
        "        tgt_input = encoding_indices[:, :-1]  # Exclude last token for input\n",
        "        tgt_output = encoding_indices[:, 1:]  # Exclude first token for output (ground truth)\n",
        "        c_text = model['text_encoder'](text_input.unsqueeze(1))\n",
        "\n",
        "        # Generate memory from text encoder\n",
        "\n",
        "        # Forward pass through TransformerGraphDecoder\n",
        "        logits = model['transformer_decoder'](tgt_input, c_text)  # [batch_size, seq_len, vocab_size]\n",
        "\n",
        "        # Compute cross-entropy loss\n",
        "        loss = F.cross_entropy(\n",
        "            logits.view(-1, logits.size(-1)),  # Flatten logits\n",
        "            tgt_output.contiguous().view(-1)  # Flatten target tokens\n",
        "        )\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(data_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transformer_decoder_training(num_epochs=10, batch_size=4, learning_rate=1e-3):\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = Adam(\n",
        "        model['transformer_decoder'].parameters(),\n",
        "        lr=learning_rate,\n",
        "    )\n",
        "\n",
        "    # Load Data\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)  \n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_TD_one_epoch(model, train_loader, optimizer, device)\n",
        "        val_loss = TD_evaluate(model, val_loader, device)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "    print(\"Training Complete!\")\n",
        "\n",
        "    # Testing\n",
        "    test_loss = evaluate(model, test_loader, device)\n",
        "    print(f\"Test Loss: {test_loss:.4f}\")\n",
        "    \n",
        "# Run the training\n",
        "transformer_decoder_training()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "zNudV8IXXnku"
      },
      "outputs": [],
      "source": [
        "torch.save({name: part.state_dict() for name, part in model.items()}, \"trained_model.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [],
      "source": [
        "text_label_str = \"AR gun\"\n",
        "inputs = tokenizer(text_label_str, return_tensors=\"pt\", padding=True, truncation=True, max_length=32)\n",
        "input_ids = inputs[\"input_ids\"].to(dtype=torch.long)  # Ensure integer token IDs and move to device\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = bert_model(input_ids.to(device))  # Ensure input is on the correct device\n",
        "text_label_embedding = outputs.last_hidden_state.to(device) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_graph_from_bert(model, bert_embedding, device):\n",
        "    \"\"\"\n",
        "    Generate a graph using BERT embeddings and the codebook.\n",
        "    \n",
        "    Args:\n",
        "        model: Dictionary containing the model components.\n",
        "        bert_embedding: Tensor of shape [1, embedding_dim] from BERT.\n",
        "        device: Device to run the model on (CPU or GPU).\n",
        "    \"\"\"\n",
        "    # Move BERT embedding to the correct device\n",
        "    bert_embedding = bert_embedding.to(device)  # Shape: [1, embedding_dim]\n",
        "\n",
        "    # Quantize the BERT embedding\n",
        "    with torch.no_grad():\n",
        "        z_q, _ = model['vector_quantizer'](bert_embedding)  # Quantized representation\n",
        "\n",
        "    # Decode the quantized embeddings to generate graph\n",
        "    reconstructed_nodes, reconstructed_adj = model['graph_decoder'](z_q)\n",
        "    print(\"Reconstructed Nodes:\", reconstructed_nodes)\n",
        "    print(\"Reconstructed Adjacency Matrix:\", reconstructed_adj)\n",
        "\n",
        "    # Visualize the generated graph\n",
        "    visualize_3d(reconstructed_nodes, reconstructed_adj)\n",
        "\n",
        "# Example Usage\n",
        "generate_graph_from_bert(model, text_label_embedding, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    z_latent = torch.randn(1, 128).to(device)  # Random latent vector\n",
        "    new_nodes, new_adj = model['graph_decoder'](z_latent)\n",
        "    print(\"Generated Nodes:\", new_nodes)\n",
        "    print(\"Generated Adjacency Matrix:\", new_adj)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0cd779ddf0be49bb857bbee186a8bdb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0958f6189b4948926a236c26eb8c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1093834e1ad84e52adc3155a979bc1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebf19089e0f460aaa211c6ff1996b02",
            "placeholder": "",
            "style": "IPY_MODEL_bab982ff160a4d73b993ed5db2c49218",
            "value": "model.safetensors:100%"
          }
        },
        "134d780ed6c64778a4ce565339b61686": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2397f1d2773d46ba8a3f408208293888": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24027343e539405a95bb88f4cf0d5044": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "297b8c9d245f42a4864d853f0674aae6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cb580877af43e586f4d76c288a6380": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e6617cbf36c4e91973b888cd244bf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e9b5736d2414acda9d15ac96473c885": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "337eb33f480440a48149ce9c1a1aa4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "36355540013a4f78be3ca41e44b6926d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37ade2c5ac3e4fd38a02200c84bac548": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "382bc7f77d0d47f9ae4bbb00a40128e5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c8fafad03b49b993b1569ca396197b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5971a7ddd8594a5cb9ec060168bc14ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5bbb1a78cf5b49feb35d9f1a3a55a8db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5d15e1ab66e147eeb027ebf9d86bc435": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ee3cfc2d2a64a5286907d9d1e1c5a13": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "607db37930064289878b1791b8ac7bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f0958f6189b4948926a236c26eb8c5f",
            "placeholder": "",
            "style": "IPY_MODEL_337eb33f480440a48149ce9c1a1aa4a6",
            "value": "466k/466k[00:00&lt;00:00,13.8MB/s]"
          }
        },
        "6cbde44d11334b5b944c8410c8cb0d38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ebf19089e0f460aaa211c6ff1996b02": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ec9249ba6364b8eb9c8cdee07d62f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37ade2c5ac3e4fd38a02200c84bac548",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8efdfafa7594d648715b7388115b6bc",
            "value": 48
          }
        },
        "7bb00053b88d47d684ded22fc79b7061": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab44d06347094ed5bc15e5ee232eac5f",
            "placeholder": "",
            "style": "IPY_MODEL_c2dcb84419e84f4c94b062e256c60fc7",
            "value": "tokenizer_config.json:100%"
          }
        },
        "8002c62e95af4128b45b4759fd1ae9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9a0986b39f6486f8a1ebcc597d744ba",
            "placeholder": "",
            "style": "IPY_MODEL_2e6617cbf36c4e91973b888cd244bf2b",
            "value": "440M/440M[00:03&lt;00:00,185MB/s]"
          }
        },
        "90e0bb2fe52e4080be9913569e83c314": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cbde44d11334b5b944c8410c8cb0d38",
            "placeholder": "",
            "style": "IPY_MODEL_f43b792d1ac142b4b29d3a6081b89646",
            "value": "tokenizer.json:100%"
          }
        },
        "90fe37851c7a47138a7006eb54fcdd4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97bdf1a4b7424908b96bd0454cd3a708": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97c440d79b63422bb1653f7f06a1a079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b21fdc01b76b484f88ebff488171588a",
              "IPY_MODEL_d56aa33f2cf843109608aad4a243c294",
              "IPY_MODEL_c7ca3809b88b4a0b8668897452dbda7c"
            ],
            "layout": "IPY_MODEL_2e9b5736d2414acda9d15ac96473c885"
          }
        },
        "97c786a45441467b8d874fe5c25c6126": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc7945f033b24db089f116da7ac98aeb",
              "IPY_MODEL_9892b898f51540098e2fc72b6a41ebce",
              "IPY_MODEL_d68069b8111e47b69365b3e3760d1edf"
            ],
            "layout": "IPY_MODEL_29cb580877af43e586f4d76c288a6380"
          }
        },
        "97e43e3f2ff4430589ce42ac608b790c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1093834e1ad84e52adc3155a979bc1a8",
              "IPY_MODEL_9db512326f264814aa7c1172dc6c8ea3",
              "IPY_MODEL_8002c62e95af4128b45b4759fd1ae9a7"
            ],
            "layout": "IPY_MODEL_9de36e3c313a4a789a849204162e18dc"
          }
        },
        "9892b898f51540098e2fc72b6a41ebce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36355540013a4f78be3ca41e44b6926d",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2a056a85c984797b34fa0fdb45a1298",
            "value": 570
          }
        },
        "9db512326f264814aa7c1172dc6c8ea3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_382bc7f77d0d47f9ae4bbb00a40128e5",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5bbb1a78cf5b49feb35d9f1a3a55a8db",
            "value": 440449768
          }
        },
        "9de36e3c313a4a789a849204162e18dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2a056a85c984797b34fa0fdb45a1298": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab44d06347094ed5bc15e5ee232eac5f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0658da51e9645af95ce49e50281cc6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21fdc01b76b484f88ebff488171588a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51c8fafad03b49b993b1569ca396197b",
            "placeholder": "",
            "style": "IPY_MODEL_b628ae7a8f6544c286311ac4cae11eed",
            "value": "vocab.txt:100%"
          }
        },
        "b628ae7a8f6544c286311ac4cae11eed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9b1310b2cc844b58d36f03ce2121df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ee3cfc2d2a64a5286907d9d1e1c5a13",
            "placeholder": "",
            "style": "IPY_MODEL_2397f1d2773d46ba8a3f408208293888",
            "value": "48.0/48.0[00:00&lt;00:00,1.15kB/s]"
          }
        },
        "bab982ff160a4d73b993ed5db2c49218": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd21d9d2bfed40d8887ff97cbb571205": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2dcb84419e84f4c94b062e256c60fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7ca3809b88b4a0b8668897452dbda7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d230aec0b9c540cc892ecd07012c404e",
            "placeholder": "",
            "style": "IPY_MODEL_134d780ed6c64778a4ce565339b61686",
            "value": "232k/232k[00:00&lt;00:00,5.08MB/s]"
          }
        },
        "cc7945f033b24db089f116da7ac98aeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d15e1ab66e147eeb027ebf9d86bc435",
            "placeholder": "",
            "style": "IPY_MODEL_f1b416f44ddd4b4c9df5eef75978c6f4",
            "value": "config.json:100%"
          }
        },
        "d230aec0b9c540cc892ecd07012c404e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d56aa33f2cf843109608aad4a243c294": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd21d9d2bfed40d8887ff97cbb571205",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97bdf1a4b7424908b96bd0454cd3a708",
            "value": 231508
          }
        },
        "d68069b8111e47b69365b3e3760d1edf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_297b8c9d245f42a4864d853f0674aae6",
            "placeholder": "",
            "style": "IPY_MODEL_24027343e539405a95bb88f4cf0d5044",
            "value": "570/570[00:00&lt;00:00,14.1kB/s]"
          }
        },
        "dbad3e0bf4104835abeb6966d9865d66": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90fe37851c7a47138a7006eb54fcdd4d",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5971a7ddd8594a5cb9ec060168bc14ac",
            "value": 466062
          }
        },
        "e688fbce31824171994232209d5c43c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90e0bb2fe52e4080be9913569e83c314",
              "IPY_MODEL_dbad3e0bf4104835abeb6966d9865d66",
              "IPY_MODEL_607db37930064289878b1791b8ac7bd4"
            ],
            "layout": "IPY_MODEL_b0658da51e9645af95ce49e50281cc6d"
          }
        },
        "e8efdfafa7594d648715b7388115b6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f14f5a8c778a4393933842e6737cb631": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7bb00053b88d47d684ded22fc79b7061",
              "IPY_MODEL_6ec9249ba6364b8eb9c8cdee07d62f28",
              "IPY_MODEL_b9b1310b2cc844b58d36f03ce2121df6"
            ],
            "layout": "IPY_MODEL_0cd779ddf0be49bb857bbee186a8bdb5"
          }
        },
        "f1b416f44ddd4b4c9df5eef75978c6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f43b792d1ac142b4b29d3a6081b89646": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9a0986b39f6486f8a1ebcc597d744ba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
